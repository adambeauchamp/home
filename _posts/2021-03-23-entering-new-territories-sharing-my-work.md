---
layout: post
title:  "Entering New Territories: Sharing My Work"
date:   2021-03-23 17:00:00 -0500
categories: TPUS
tags: Florida, data cleaning
---

Earlier this month I introduced a project to use topic modeling on a set of published primary source documents, *The Territorial Papers of the United States*, in particular the five volumes that focus on the territory of Florida, 1821-1845. This projected started within the context of a graduate course on Computational Methods in the Humanitites, led by Dr. Will Hanley at Florida State University, but will continue beyond the semester. This post marks the first time I will publish some of my work-in-progress on this website and in my GitHub repository. 

As I learned to use regular expressions, text editing programs, and GitHub itself, I focused on cleaning the plain text file of Volume 22, the first in *TPUS* to collate documents about the territory of Florida, acquired from Spain by treaty in 1819 and officially occupied beginning in 1821. It became apparent that the structure of this published set of documents lent itself to structuring the text itself with eXtensible Markup Language (XML). Since each transcribed and published document had a header, a citation to its source archive, and usually a date in some format, I devised a tagging system to mark off these metadata, distinct but still attached to the body of each document.

### Touring the Repository 
I envision my work with the *Territorial Papers of the United States* as just a first step in a broader investigation of the shape of archives that have shaped our understanding the past. Published sets of documents are just one aspect of this. I'm interested in exploring how the selection process was both a response to understandings of history at the time they were published and subsequently influenced future histories, especially as collections like the *TPUS* came in and out of fashion with professional historians. Therefore, I have named this GitHub repository [Archives Assemble Florida](https://github.com/adambeauchamp/archives-assemble-florida) since it will eventually expand beyong the TPUS. The ``README.md`` file at this level describes the overall project in broadest terms. 

The next folder in the respository's hierarchy is named **TPUS**. Here are the texts I've cleaned and rendered into XML formats thus far from the *TPUS* volumes, including several intermediary products. I have detailed each step I took, each FIND and REPLACE acheived either by regular expressions or by hand, in the ``ReadMe.md`` file in this TPUS folder. I have separate folders here for the various byproducts of the cleaning process, mostly to keep things organized and to set aside (but preserve) earlier iterations of the texts. For example, the original plain text files I downloaded from [HathiTrust](https://www.hathitrust.org) are kept, unmodified, in one folder. In another are all the front matter, footnotes, and indices that I separated and exclude from future analysis. After that I began marking up the plain text, beginning the structuring process that distinguishes metadata from documentary texts within each volume. These marked up files are saved as ``.txt`` files in the last step before transforming them into XML files.

As of this writing, the folder for the XML files only includes one: the file for volume 22. This was the first volume I worked through and is the only one completed with the full set of XML tags. I am using the detailed instructions I wrote while cleaning volume 22 to perform the same transformations on volumes 23, 24, 25, and 26, completing the documentary set for Florida. I will add these files as they are completed. There is also a folder for CSV files, the next step when I take the XML files and use Open Refine to standardize some of the metadata across documents. These can be used to visualize which archives are the major sources for the published *TPUS* project and some aspects of the documents themselves.